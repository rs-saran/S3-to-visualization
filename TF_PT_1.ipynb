{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNP4BwupEd0G9T28q5LSTR4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rs-saran/S3-to-visualization/blob/main/TF_PT_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import torch"
      ],
      "metadata": {
        "id": "oQ4Xjmoj41XK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 01. Tensors"
      ],
      "metadata": {
        "id": "5Fb0dauAAGS_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9kITG8V4vBY",
        "outputId": "dd0d6875-6f80-47b3-9671-aee68b98c41c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector: tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32)\n",
            "Zeros: tf.Tensor([0. 0. 0.], shape=(3,), dtype=float32)\n",
            "Ones: tf.Tensor([1. 1. 1.], shape=(3,), dtype=float32)\n",
            "Range: tf.Tensor([0 1 2 3 4], shape=(5,), dtype=int32)\n",
            "Vector: tensor([1., 2., 3.])\n",
            "Zeros: tensor([0., 0., 0.])\n",
            "Ones: tensor([1., 1., 1.])\n",
            "Range: tensor([0, 1, 2, 3, 4])\n"
          ]
        }
      ],
      "source": [
        "#Basic Vector Handling\n",
        "\n",
        "# Create tensors\n",
        "vector1 = tf.constant([1.0, 2.0, 3.0]) #immuntable\n",
        "a = tf.Variable([1.0, 2.0, 3.0]) #mutable\n",
        "zeros1 = tf.zeros(3)\n",
        "ones1 = tf.ones(3)\n",
        "range_vector1 = tf.range(0, 5, delta=1)  # Similar to Python's range\n",
        "print(\"Vector:\", vector1)\n",
        "print(\"Zeros:\", zeros1)\n",
        "print(\"Ones:\", ones1)\n",
        "print(\"Range:\", range_vector1)\n",
        "\n",
        "\n",
        "# Create constant tensors\n",
        "vector = torch.tensor([1.0, 2.0, 3.0]) #mutable\n",
        "zeros = torch.zeros(3)\n",
        "ones = torch.ones(3)\n",
        "range_vector = torch.arange(0, 5, step=1)  # Similar to Python's range\n",
        "print(\"Vector:\", vector)\n",
        "print(\"Zeros:\", zeros)\n",
        "print(\"Ones:\", ones)\n",
        "print(\"Range:\", range_vector)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape a vector\n",
        "matrix = tf.reshape(tf.range(6), (2, 3))\n",
        "print(\"Matrix:\\n\", matrix)\n",
        "\n",
        "# Transpose\n",
        "transposed = tf.transpose(matrix)\n",
        "print(\"Transposed Matrix:\\n\", transposed)\n",
        "\n",
        "\n",
        "# Reshape a vector\n",
        "matrix = torch.arange(6).reshape(2, 3)\n",
        "print(\"Matrix:\\n\", matrix)\n",
        "\n",
        "# Transpose\n",
        "transposed = matrix.T  # Or matrix.transpose(0, 1)\n",
        "print(\"Transposed Matrix:\\n\", transposed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2B6iAHz5cey",
        "outputId": "5c3703ae-1383-4862-cb2d-7477cd61c7c0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix:\n",
            " tf.Tensor(\n",
            "[[0 1 2]\n",
            " [3 4 5]], shape=(2, 3), dtype=int32)\n",
            "Transposed Matrix:\n",
            " tf.Tensor(\n",
            "[[0 3]\n",
            " [1 4]\n",
            " [2 5]], shape=(3, 2), dtype=int32)\n",
            "Matrix:\n",
            " tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "Transposed Matrix:\n",
            " tensor([[0, 3],\n",
            "        [1, 4],\n",
            "        [2, 5]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Broadcasting addition\n",
        "a = tf.constant([1, 2, 3])\n",
        "b = tf.constant([[10,20,30]])\n",
        "result = a + b\n",
        "print(\"Broadcasted Result:\\n\", result)\n",
        "\n",
        "# Broadcasting addition\n",
        "a = torch.tensor([1, 2, 3])\n",
        "b = torch.tensor([[10], [20], [30]])\n",
        "result = a + b\n",
        "print(\"Broadcasted Result:\\n\", result)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0J4t8rT50r-",
        "outputId": "ed13c740-2b5e-45da-b5f1-714d3e221109"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Broadcasted Result:\n",
            " tf.Tensor([[11 22 33]], shape=(1, 3), dtype=int32)\n",
            "Broadcasted Result:\n",
            " tensor([[11, 12, 13],\n",
            "        [21, 22, 23],\n",
            "        [31, 32, 33]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.constant([1.0, 2.0, 3.0])\n",
        "b = tf.constant([4.0, 5.0, 6.0])\n",
        "\n",
        "# Addition, subtraction, multiplication, and division\n",
        "# add = tf.add(a, b)\n",
        "# subtract = tf.subtract(a, b)\n",
        "# multiply = tf.multiply(a, b)\n",
        "# divide = tf.divide(a, b)\n",
        "\n",
        "add = a + b\n",
        "subtract = a - b\n",
        "multiply = a * b\n",
        "divide = a / b\n",
        "print(\"Add:\", add)\n",
        "print(\"Subtract:\", subtract)\n",
        "print(\"Multiply:\", multiply)\n",
        "print(\"Divide:\", divide)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVWVcejM6dCt",
        "outputId": "8558249b-25b5-4907-eb7c-8517e994c097"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Add: tf.Tensor([5. 7. 9.], shape=(3,), dtype=float32)\n",
            "Subtract: tf.Tensor([-3. -3. -3.], shape=(3,), dtype=float32)\n",
            "Multiply: tf.Tensor([ 4. 10. 18.], shape=(3,), dtype=float32)\n",
            "Divide: tf.Tensor([0.25 0.4  0.5 ], shape=(3,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([1.0, 2.0, 3.0])\n",
        "b = torch.tensor([4.0, 5.0, 6.0])\n",
        "\n",
        "# Addition, subtraction, multiplication, and division\n",
        "add = a + b\n",
        "subtract = a - b\n",
        "multiply = a * b\n",
        "divide = a / b\n",
        "print(\"Add:\", add)\n",
        "print(\"Subtract:\", subtract)\n",
        "print(\"Multiply:\", multiply)\n",
        "print(\"Divide:\", divide)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aT99pGAY5_kX",
        "outputId": "24cefcb8-730f-43e3-efc8-21460d496e32"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Add: tensor([5., 7., 9.])\n",
            "Subtract: tensor([-3., -3., -3.])\n",
            "Multiply: tensor([ 4., 10., 18.])\n",
            "Divide: tensor([0.2500, 0.4000, 0.5000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.constant([1.0, 2.0, 3.0])\n",
        "\n",
        "# Sum, mean, and maximum\n",
        "print(\"Sum:\", tf.reduce_sum(a))\n",
        "print(\"Mean:\", tf.reduce_mean(a))\n",
        "print(\"Max:\", tf.reduce_max(a))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEggWiB46fw2",
        "outputId": "a7cfd562-4267-4218-fc21-6ec345d75335"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum: tf.Tensor(6.0, shape=(), dtype=float32)\n",
            "Mean: tf.Tensor(2.0, shape=(), dtype=float32)\n",
            "Max: tf.Tensor(3.0, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([1.0, 2.0, 3.0])\n",
        "\n",
        "# Sum, mean, and maximum\n",
        "print(\"Sum:\", torch.sum(a))\n",
        "print(\"Mean:\", torch.mean(a))\n",
        "print(\"Max:\", torch.max(a))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQ26R2HF6w2B",
        "outputId": "ffa0ca0c-6cad-4d28-b65f-a74bbaabcf95"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum: tensor(6.)\n",
            "Mean: tensor(2.)\n",
            "Max: tensor(3.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#inplace operations (present in torchwith _ suffix, not present in tf) #use cautiously could cause problem with gradient computations\n",
        "import torch\n",
        "\n",
        "# Create a tensor\n",
        "a = torch.tensor([1.0, 2.0, 3.0])\n",
        "\n",
        "# In-place addition\n",
        "a.add_(1.0)  # Adds 1.0 to each element in-place\n",
        "print(\"In-place addition:\", a)\n",
        "\n",
        "# In-place multiplication\n",
        "a.mul_(2.0)  # Multiplies each element by 2 in-place\n",
        "print(\"In-place multiplication:\", a)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RG6aodVo6zQd",
        "outputId": "8707782c-fa4f-46cb-c0bd-bdda9a5a6ee5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In-place addition: tensor([2., 3., 4.])\n",
            "In-place multiplication: tensor([4., 6., 8.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create a tensor\n",
        "a = tf.Variable([1.0, 2.0, 3.0])\n",
        "\n",
        "# Simulate in-place addition\n",
        "a.assign_add([1.0, 1.0, 1.0])  # Add 1.0 to each element\n",
        "print(\"Simulated in-place addition:\", a)\n",
        "\n",
        "# Simulate in-place multiplication\n",
        "a.assign(a * 2.0)  # Multiply each element by 2\n",
        "print(\"Simulated in-place multiplication:\", a)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-d3VzozA7-aH",
        "outputId": "fb3c3a02-6450-4aa2-b309-5e870a29fe60"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simulated in-place addition: <tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([2., 3., 4.], dtype=float32)>\n",
            "Simulated in-place multiplication: <tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([4., 6., 8.], dtype=float32)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorFlow tensor to NumPy array\n",
        "a = tf.Variable([1.0, 2.0, 3.0])\n",
        "numpy_array = a.numpy()\n",
        "print(\"NumPy array:\", numpy_array)\n",
        "\n",
        "# NumPy array to TensorFlow tensor\n",
        "b = tf.convert_to_tensor(numpy_array)\n",
        "print(\"TensorFlow tensor:\", b)\n",
        "\n",
        "# In-place changes\n",
        "numpy_array[0] = 10  # Changes DO NOT reflect in the TensorFlow tensor\n",
        "print(\"Modified NumPy array:\", numpy_array)\n",
        "print(\"Unchanged TensorFlow tensor:\", b) #remains unchanged even if we used variable/constant in a\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "107rE8pG8NeL",
        "outputId": "0193e0b9-f091-44e6-afeb-7fdf97757bb6"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy array: [1. 2. 3.]\n",
            "TensorFlow tensor: tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32)\n",
            "Modified NumPy array: [10.  2.  3.]\n",
            "Unchanged TensorFlow tensor: tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch tensor to NumPy array\n",
        "a = torch.tensor([1.0, 2.0, 3.0])\n",
        "numpy_array = a.numpy()\n",
        "print(\"NumPy array:\", numpy_array)\n",
        "\n",
        "# NumPy array to PyTorch tensor\n",
        "b = torch.from_numpy(numpy_array)\n",
        "print(\"PyTorch tensor:\", b)\n",
        "\n",
        "# In-place changes\n",
        "numpy_array[0] = 10  # Changes reflect in the PyTorch tensor\n",
        "print(\"Modified NumPy array:\", numpy_array)\n",
        "print(\"Modified PyTorch tensor:\", b) #tensor and numpy array share same memory\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kW30UWb99_1i",
        "outputId": "d1820038-90f3-42d2-b9eb-bc2ad7d52151"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy array: [1. 2. 3.]\n",
            "PyTorch tensor: tensor([1., 2., 3.])\n",
            "Modified NumPy array: [10.  2.  3.]\n",
            "Modified PyTorch tensor: tensor([10.,  2.,  3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YEMqLK2cAA49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 02. Gradients"
      ],
      "metadata": {
        "id": "rtv8TuyeABvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a trainable variable\n",
        "x = tf.Variable(3.0)\n",
        "\n",
        "# Use GradientTape to compute the gradient\n",
        "with tf.GradientTape() as tape:\n",
        "    y = x**2 + 2 * x + 1  # Compute function y = x^2 + 2x + 1\n",
        "\n",
        "# Compute dy/dx\n",
        "dy_dx = tape.gradient(y, x)\n",
        "print(\"Gradient:\", dy_dx.numpy())  # Output: 8.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wPtmgK3-SA_",
        "outputId": "cab51688-1c34-41a2-e44c-2c36f934e19d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient: 8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a trainable variable\n",
        "x = torch.tensor(3.0, requires_grad=True)\n",
        "\n",
        "# Compute function y = x^2 + 2x + 1\n",
        "y = x**2 + 2 * x + 1\n",
        "\n",
        "# Compute dy/dx\n",
        "y.backward()\n",
        "print(\"Gradient:\", x.grad.item())  # Output: 8.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQPiRlGVAL0l",
        "outputId": "6f4992c4-f620-4547-cfaa-8f12bd3606f7"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient: 8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.Variable(3.0)\n",
        "z = tf.Variable(2.0)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    y = x**2 + z**3\n",
        "\n",
        "# Compute gradients\n",
        "grads = tape.gradient(y, [x, z])\n",
        "print(\"Gradient w.r.t x:\", grads[0].numpy())  # Output: 6.0\n",
        "print(\"Gradient w.r.t z:\", grads[1].numpy())  # Output: 12.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flE0LstJARTg",
        "outputId": "1f419826-9a99-4de1-a402-4029818ff9d5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient w.r.t x: 6.0\n",
            "Gradient w.r.t z: 12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(3.0, requires_grad=True)\n",
        "z = torch.tensor(2.0, requires_grad=True)\n",
        "\n",
        "y = x**2 + z**3\n",
        "\n",
        "y.backward()\n",
        "print(\"Gradient w.r.t x:\", x.grad.item())  # Output: 6.0\n",
        "print(\"Gradient w.r.t z:\", z.grad.item())  # Output: 12.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGZ97qE_AWN3",
        "outputId": "0d8c2f9d-a9a0-40ab-bb91-d834bf99bc3d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient w.r.t x: 6.0\n",
            "Gradient w.r.t z: 12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#higher order gradient\n",
        "\n",
        "x = tf.Variable(3.0)\n",
        "\n",
        "with tf.GradientTape() as tape2:\n",
        "    with tf.GradientTape() as tape1:\n",
        "        y = x**3\n",
        "    dy_dx = tape1.gradient(y, x)  # First derivative\n",
        "d2y_dx2 = tape2.gradient(dy_dx, x)  # Second derivative\n",
        "\n",
        "print(\"First Derivative:\", dy_dx.numpy())  # Output: 27.0\n",
        "print(\"Second Derivative:\", d2y_dx2.numpy())  # Output: 18.0\n",
        "\n",
        "x = torch.tensor(3.0, requires_grad=True)\n",
        "\n",
        "y = x**3\n",
        "dy_dx = torch.autograd.grad(y, x, create_graph=True)[0]  # First derivative\n",
        "d2y_dx2 = torch.autograd.grad(dy_dx, x)[0]  # Second derivative\n",
        "\n",
        "print(\"First Derivative:\", dy_dx.item())  # Output: 27.0\n",
        "print(\"Second Derivative:\", d2y_dx2.item())  # Output: 18.0\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAuZxGNVAZhb",
        "outputId": "5d0bf854-7666-4c6f-ce04-2284b36eefcd"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Derivative: 27.0\n",
            "Second Derivative: 18.0\n",
            "First Derivative: 27.0\n",
            "Second Derivative: 18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# by default, gradients accumulate in PyTorch, while in TensorFlow, they don't unless explicitly handled.\n",
        "x = torch.tensor(3.0, requires_grad=True)\n",
        "\n",
        "# Compute gradients twice\n",
        "y1 = x**2\n",
        "y1.backward()  # Grad: 6.0\n",
        "\n",
        "y2 = x**3\n",
        "y2.backward()  # Grad: 27.0\n",
        "\n",
        "print(\"Accumulated Gradient:\", x.grad.item())  # Output: 33.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpsyPJjyAkAD",
        "outputId": "a919da4f-0913-49f3-8da2-89041cdae403"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accumulated Gradient: 33.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.Variable(3.0)\n",
        "\n",
        "# Use separate tapes to accumulate gradients\n",
        "with tf.GradientTape() as tape1:\n",
        "    y1 = x**2\n",
        "grad1 = tape1.gradient(y1, x)\n",
        "\n",
        "with tf.GradientTape() as tape2:\n",
        "    y2 = x**3\n",
        "grad2 = tape2.gradient(y2, x)\n",
        "\n",
        "# Accumulate manually\n",
        "accumulated_grad = grad1 + grad2\n",
        "print(\"Accumulated Gradient:\", accumulated_grad.numpy())  # Output: 33.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxwecC6jAxqi",
        "outputId": "54d6367c-bd3c-47e5-b75a-1618ddc1840b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accumulated Gradient: 33.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#5. Stop Gradient\n",
        "x = tf.Variable(3.0)\n",
        "with tf.GradientTape() as tape:\n",
        "    y = x**2\n",
        "    z = tf.stop_gradient(y) * 3  # No gradient contribution from y\n",
        "grad = tape.gradient(z, x)\n",
        "print(\"Gradient:\", grad.numpy())  # Output: 0.0\n",
        "\n",
        "x = torch.tensor(3.0, requires_grad=True)\n",
        "y = x**2\n",
        "with torch.no_grad():  # No gradient contribution from y\n",
        "    z = y * 3\n",
        "z.backward()\n",
        "print(\"Gradient:\", x.grad)  # Output: None or 0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "j_fGEMgDNJWb",
        "outputId": "9d412892-d44a-4a01-ba72-43c4f421f79b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'numpy'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-8493353bf0b3>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m3\u001b[0m  \u001b[0;31m# No gradient contribution from y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Gradient:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Output: 0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'numpy'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "| Feature                  | TensorFlow                              | PyTorch                               |\n",
        "|--------------------------|-----------------------------------------|---------------------------------------|\n",
        "| Gradient Calculation     | `tf.GradientTape()`                    | `.backward()`                        |\n",
        "| Gradient Accumulation    | Doesn't accumulate by default          | Accumulates by default               |\n",
        "| Higher-Order Gradients   | Nested `GradientTape`                  | `create_graph=True`                  |\n",
        "| Stop Gradient            | `tf.stop_gradient()`                   | `torch.no_grad()`                    |\n"
      ],
      "metadata": {
        "id": "2DreuDEeOT4U"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WpLFnRsZN6o-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 03. Buliding Model Layers"
      ],
      "metadata": {
        "id": "_0JLnnNlOrx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a Sequential model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(32, activation='relu', input_shape=(128,1)),  # Input layer\n",
        "    tf.keras.layers.Dense(64, activation='relu'),                     # Hidden layer\n",
        "    tf.keras.layers.Dense(10, activation='softmax')                   # Output layer\n",
        "])\n",
        "\n",
        "# Model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "Q2kfcVwTOwUh",
        "outputId": "2167b5c9-705e-4dc1-e973-75847585c525"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │              \u001b[38;5;34m64\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m2,112\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │             \u001b[38;5;34m650\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,826\u001b[0m (11.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,826</span> (11.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,826\u001b[0m (11.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,826</span> (11.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# Define a Sequential model\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(128, 32),  # Input layer\n",
        "    nn.ReLU(),           # Activation\n",
        "    nn.Linear(32, 64),   # Hidden layer\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 10),   # Output layer\n",
        "    nn.Softmax(dim=1)    # Activation for multi-class classification\n",
        ")\n",
        "\n",
        "# Print model architecture\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGq1HhlXQdOY",
        "outputId": "86acb1cf-bb7f-4843-da6d-f72f4c4134ca"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=128, out_features=32, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=32, out_features=64, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
            "  (5): Softmax(dim=1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(CustomModel, self).__init__()\n",
        "        self.dense1 = tf.keras.layers.Dense(32, activation='relu')\n",
        "        self.dense2 = tf.keras.layers.Dense(64, activation='relu')\n",
        "        self.output_layer = tf.keras.layers.Dense(10, activation='softmax')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.dense1(inputs)\n",
        "        x = self.dense2(x)\n",
        "        return self.output_layer(x)\n",
        "\n",
        "# Create an instance of the model\n",
        "model = CustomModel()\n"
      ],
      "metadata": {
        "id": "lJ4BygglSEUs"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomModel, self).__init__()\n",
        "        self.dense1 = nn.Linear(128, 32)\n",
        "        self.dense2 = nn.Linear(32, 64)\n",
        "        self.output_layer = nn.Linear(64, 10)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.dense1(x))\n",
        "        x = torch.relu(self.dense2(x))\n",
        "        return self.softmax(self.output_layer(x))\n",
        "\n",
        "# Create an instance of the model\n",
        "model = CustomModel()\n"
      ],
      "metadata": {
        "id": "b5WwL3-ASP7F"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "class ConvModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvModel, self).__init__()\n",
        "        self.conv = nn.Conv2d(3, 32, kernel_size=3, activation='relu')\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(32 * 31 * 31, 64)  # 31 = (input_dim - kernel + 1) / pool\n",
        "        self.fc2 = nn.Linear(64, 10)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv(x))\n",
        "        x = self.pool(x)\n",
        "        x = self.flatten(x)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        return self.softmax(self.fc2(x))\n",
        "\n",
        "model = ConvModel()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "82PPdMtcSScd",
        "outputId": "7961e338-7d68-4bb2-f679-a806b40ac30d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Conv2d.__init__() got an unexpected keyword argument 'activation'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-64717d708495>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-53-64717d708495>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConvModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Conv2d.__init__() got an unexpected keyword argument 'activation'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "\n",
        "| **Use Case**                       | **Sequential API**                     | **Class-Based Model**                     |\n",
        "|------------------------------------|----------------------------------------|------------------------------------------|\n",
        "| **Simple Feedforward Networks**    | ✅                                      | ❌                                        |\n",
        "| **Complex Architectures**          | ❌                                      | ✅                                        |\n",
        "| **Dynamic Logic (e.g., Loops)**    | ❌                                      | ✅                                        |\n",
        "| **Multiple Inputs/Outputs**        | ❌                                      | ✅                                        |\n",
        "| **Custom Layers/Operations**       | ❌                                      | ✅                                        |\n",
        "| **Layer Sharing**                  | ❌                                      | ✅                                        |\n",
        "| **Ease of Use & Rapid Prototyping**| ✅                                      | ❌                                        |\n",
        "| **Control Over Forward Pass**      | ❌                                      | ✅                                        |\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "4_DVEnL8VGLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Why only forward function defined in Class and not backward?\n",
        "# When you perform operations in the forward pass, the frameworks record a computation graph (a dynamic graph in PyTorch and a static/eager graph in TensorFlow).\n",
        "#During backpropagation, the frameworks traverse this computation graph automatically to compute gradients using reverse-mode automatic differentiation (a.k.a. backpropagation)."
      ],
      "metadata": {
        "id": "kijAlZBEVIuS"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Names should be forward and call, should not be changed"
      ],
      "metadata": {
        "id": "qVKzkSrLV9yH"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.custom_gradient\n",
        "def custom_square(x):\n",
        "    def grad(dy):\n",
        "        return 2.5 * x * dy  # Define custom gradient, here dy indicates gradient coming from the next layer (L+1 -> L) during backproagation\n",
        "    return tf.square(x), grad\n",
        "\n",
        "class CustomLayer(tf.keras.layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        return custom_square(inputs)\n",
        "\n",
        "# Use the custom operation\n",
        "x = tf.Variable([2.0])\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    y = CustomLayer().call(x)\n",
        "grad = tape.gradient(y, x)\n",
        "print(x,y,grad)  # Output: tensor([4.])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFy5M4uDWja5",
        "outputId": "5af689bd-cba9-4d1a-ba86-6e47a5842933"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([2.], dtype=float32)> tf.Tensor([4.], shape=(1,), dtype=float32) tf.Tensor([5.], shape=(1,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.autograd import Function\n",
        "\n",
        "class CustomSquare2(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x):\n",
        "        ctx.save_for_backward(x)  # Save input for backward pass\n",
        "        return x ** 2\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        x, = ctx.saved_tensors\n",
        "        return 3 * x * grad_output  # Custom gradient logic\n",
        "\n",
        "# Use the custom operation\n",
        "x = torch.tensor([2.0], requires_grad=True)\n",
        "y = CustomSquare2.apply(x)\n",
        "y.backward()\n",
        "print(x,y,x.grad)  # Output: tensor([4.])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WD4H3xzMWplW",
        "outputId": "f15d1f0d-d5bd-4a70-b6c7-ee91fb9df955"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.], requires_grad=True) tensor([4.], grad_fn=<CustomSquare2Backward>) tensor([6.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(128, 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "\n",
        "        # Applying Xavier Uniform initialization\n",
        "        init.xavier_uniform_(self.fc1.weight)\n",
        "        init.xavier_uniform_(self.fc2.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "# Create a model and initialize weights\n",
        "model = SimpleNN()\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZr0YCD_W2TT",
        "outputId": "5ab1e2c5-2d82-4af8-a87e-60eb6b227c35"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleNN(\n",
            "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class SimpleNN1(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN1, self).__init__()\n",
        "        self.fc1 = tf.keras.layers.Dense(64, activation='relu', input_dim=128)  # First layer\n",
        "        self.fc2 = tf.keras.layers.Dense(32, activation='relu')                  # Second layer\n",
        "        self.fc3 = tf.keras.layers.Dense(10, activation='softmax')               # Output layer\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = tf.nn.relu(self.fc1(inputs))  # Apply ReLU after first layer\n",
        "        x = tf.nn.relu(self.fc2(x))      # Apply ReLU after second layer\n",
        "        return self.fc3(x)               # Return output\n",
        "\n",
        "# Create the model instance\n",
        "model = SimpleNN1()\n",
        "\n",
        "# Use `build` with input shape or pass dummy input data\n",
        "model.build((None, 128))  # Here (None, 128) means batch size can vary, input size is 128\n",
        "\n",
        "# Now call model.summary()\n",
        "model.summary()  # Batch size of None, input size of 128"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "JQvY8ClibX5h",
        "outputId": "17d33a71-85b9-47d3-cebc-6d42244bc7f6"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:391: UserWarning: `build()` was called on layer 'simple_nn1_5', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"simple_nn1_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"simple_nn1_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_32 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_33 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_34 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pass a batch of data (e.g., with shape (32, 128)) to the model\n",
        "dummy_input = tf.random.normal((32, 128))\n",
        "model(dummy_input)\n",
        "\n",
        "# Now call model.summary()\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "kIW3nFAZbmaA",
        "outputId": "cf7339dd-cdd8-4d5a-8135-71a30f24b9f3"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"simple_nn_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"simple_nn_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)                     │           \u001b[38;5;34m8,256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)                     │           \u001b[38;5;34m2,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m10\u001b[0m)                     │             \u001b[38;5;34m330\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,666\u001b[0m (41.66 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,666</span> (41.66 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,666\u001b[0m (41.66 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,666</span> (41.66 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Optimizers: just how to adjust the parameters based on gradient\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "model = SimpleNN()  # Assuming a model is defined\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n"
      ],
      "metadata": {
        "id": "gyoVvpNVcioe"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleNN1()\n",
        "# Compile the model with the Adam optimizer\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfcUXx-KeYk3",
        "outputId": "a8e62f67-60c7-48fb-ce69-60c9c4429f6a"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Zse163XettT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Training, testing and inference loops"
      ],
      "metadata": {
        "id": "cMxVDcP_fv-D"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mtXTPsPPf0Pv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}